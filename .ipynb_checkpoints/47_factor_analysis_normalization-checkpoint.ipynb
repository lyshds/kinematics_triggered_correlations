{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "#import pandas as pd\n",
    "###from sklearn.datasets import load_iris\n",
    "#from factor_analyzer import FactorAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imager/.local/lib/python2.7/site-packages/pandas/core/computation/__init__.py:18: UserWarning: The installed version of numexpr 2.4.3 is not supported in pandas and will be not be used\n",
      "The minimum supported version is 2.4.6\n",
      "\n",
      "  ver=ver, min_ver=_MIN_NUMEXPR_VERSION), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import flylib as flb\n",
    "#from thllib import flylib as flb\n",
    "import flylib as flb\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "from flylib import util\n",
    "import figurefirst as fifi\n",
    "import scipy.signal\n",
    "#import local_project_functions as lpf\n",
    "from IPython.display import SVG,display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making dataframe for fly number 1706\n",
      "Making dataframe for fly number 1707\n",
      "Making dataframe for fly number 1708\n",
      "Making dataframe for fly number 1711\n",
      "Making dataframe for fly number 1712\n",
      "Making dataframe for fly number 1713\n",
      "Making dataframe for fly number 1715\n",
      "Making dataframe for fly number 1716\n",
      "Making dataframe for fly number 1717\n",
      "Making dataframe for fly number 1718\n",
      "Making dataframe for fly number 1719\n",
      "Making dataframe for fly number 1720\n",
      "Making dataframe for fly number 1721\n",
      "Making dataframe for fly number 1722\n",
      "Making dataframe for fly number 1723\n",
      "Making dataframe for fly number 1724\n",
      "Making dataframe for fly number 1725\n",
      "Making dataframe for fly number 1726\n",
      "Making dataframe for fly number 1729\n"
     ]
    }
   ],
   "source": [
    "#fly_nums = range(1556,1565) + range(1566, 1567)#,1545)\n",
    "#fly_nums = range(1566, 1570)\n",
    "#multi_fly_df = util.construct_multi_fly_df(fly_nums)\n",
    "#df = multi_fly_df\n",
    "\n",
    "\n",
    "#fly_nums = range(1389,1402)#,1545)\n",
    "#multi_fly_df = util.construct_multi_fly_df(fly_nums)\n",
    "\n",
    "\n",
    "fly_nums = range(1706, 1709) + range(1711, 1714) + range (1715, 1719) + range(1719, 1722) + range(1722, 1727) + range(1729, 1730)# +   range(1731, 1732)## last one are the newest trials -- \n",
    "#figure out whats wrong with kine cam?\n",
    "multi_fly_df = util.construct_multi_fly_df(fly_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t' 'stimulus' 'amp_diff' 'left_amp' 'right_amp' 'fly_num' 'wbf'\n",
      " 'experimental_condition' 'pr_left' 'tpd_left' 'nm_left' 'iii1_left'\n",
      " 'iii3_left' 'i2_left' 'hg2_left' 'hg3_left' 'hg1_left' 'i1_left'\n",
      " 'bkg_left' 'b1_left' 'b2_left' 'b3_left' 'iii24_left' 'hg4_left'\n",
      " 'pr_right' 'tpd_right' 'nm_right' 'iii1_right' 'iii3_right' 'i2_right'\n",
      " 'hg2_right' 'hg3_right' 'hg1_right' 'i1_right' 'bkg_right' 'b1_right'\n",
      " 'b2_right' 'b3_right' 'iii24_right' 'hg4_right']\n",
      "['exc_cl_starfield, g_x = 1, g_y=0, b_x =0, b_y = 0, ch=0'\n",
      " 'pitch_down_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'\n",
      " 'pitch_up_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'\n",
      " 'pretrial_stripe_fix'\n",
      " 'roll_clockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'\n",
      " 'roll_counterclockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'\n",
      " 'trials_ended' 'yaw_left, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'\n",
      " 'yaw_right, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n"
     ]
    }
   ],
   "source": [
    "print(multi_fly_df.columns.values)\n",
    "print(np.unique(multi_fly_df['stimulus']))\n",
    "\n",
    "idx = (multi_fly_df['stimulus']=='cl_blocks, g_x=-1, g_y=0, b_x=-8, b_y=0, ch=True')& \\\n",
    "        ((multi_fly_df['amp_diff']>0.1)&(multi_fly_df['amp_diff']<0.104))\n",
    "\n",
    "\n",
    "# double_filtered_df = multi_fly_df.loc[idx]\n",
    "# print(double_filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b1_right', 'b1_left', 'b2_right', 'b2_left', 'b3_right', 'b3_left', 'bkg_right', 'bkg_left', 'hg1_right', 'hg1_left', 'hg2_right', 'hg2_left', 'hg3_right', 'hg3_left', 'hg4_right', 'hg4_left', 'i1_right', 'i1_left', 'i2_right', 'i2_left', 'iii1_right', 'iii1_left', 'iii24_right', 'iii24_left', 'iii3_right', 'iii3_left', 'nm_right', 'nm_left', 'pr_right', 'pr_left', 'tpd_right', 'tpd_left']\n"
     ]
    }
   ],
   "source": [
    "#print(filtered_df[key+'_right'])\n",
    "\n",
    "#flynumbers = list(range(1389,1402))\n",
    "#flynumbers = list(range(1548,1549))\n",
    "#flylist = [flb.NetFly(fnum,rootpath='/media/imager/FlyDataD/FlyDB/') for fnum in flynumbers]\n",
    "#l = [fly.open_signals() for fly in flylist]\n",
    "#fly = flylist[4]\n",
    "#fly.open_signals()\n",
    "fly = flb.NetFly(1556)\n",
    "fly.open_signals()\n",
    "\n",
    "general_sorted_keys = sorted(fly.ca_cam_left_model_fits.keys())\n",
    "#print(sorted(fly.ca_cam_left_model_fits.keys()))\n",
    "\n",
    "sorted_keys = []\n",
    "\n",
    "for key in general_sorted_keys:\n",
    "    key2= key+'_right'\n",
    "    key3= key+'_left'\n",
    "    sorted_keys.append(key2)\n",
    "    sorted_keys.append(key3)\n",
    "    \n",
    "print(sorted_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn_left = multi_fly_df.loc[multi_fly_df['stimulus']== 'cl_blocks, g_x=-1, g_y=0 b_x=-8, b_y=0']\n",
    "#turn_right = multi_fly_df.loc[multi_fly_df['stimulus']== 'cl_blocks, g_x=-1, g_y=0 b_x=8, b_y=0']\n",
    "#WSA_increase = multi_fly_df.loc[multi_fly_df['stimulus']== 'ol_blocks, g_x=0, g_y=4 b_x=0, b_y=0']\n",
    "#WSA_decrease = multi_fly_df.loc[multi_fly_df['stimulus']== 'ol_blocks, g_x=0, g_y=-4 b_x=0, b_y=0']\n",
    "\n",
    "\n",
    "\n",
    "yaw_left = multi_fly_df.loc[multi_fly_df['stimulus']== 'yaw_left, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "yaw_right = multi_fly_df.loc[multi_fly_df['stimulus']== 'yaw_right, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "pitch_up = multi_fly_df.loc[multi_fly_df['stimulus']== 'pitch_up_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "pitch_down = multi_fly_df.loc[multi_fly_df['stimulus']== 'pitch_down_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "roll_cw = multi_fly_df.loc[multi_fly_df['stimulus']== 'roll_clockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "roll_ccw = multi_fly_df.loc[multi_fly_df['stimulus']== 'roll_counterclockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#yaw_left= multi_fly_df.loc[multi_fly_df['stimulus']== 'yaw_left, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'] \n",
    "#yaw_right= multi_fly_df.loc[multi_fly_df['stimulus']== 'yaw_right, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'] \n",
    "#pitch_up =  multi_fly_df.loc[multi_fly_df['stimulus']== 'roll_clockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'] \n",
    "#pitch_down =  multi_fly_df.loc[multi_fly_df['stimulus']== 'roll_counterclockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'] \n",
    "#roll_cw =  multi_fly_df.loc[multi_fly_df['stimulus']== 'pitch_up_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0'] \n",
    "#roll_ccw =  multi_fly_df.loc[multi_fly_df['stimulus']== 'pitch_down_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "#ol_stripe_left = multi_fly_df.loc[multi_fly_df['stimulus']== 'ol_stripe, g_x=-70, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "#ol_stripe_right = multi_fly_df.loc[multi_fly_df['stimulus']== 'ol_stripe, g_x=70, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "#stripe_fix = multi_fly_df.loc[multi_fly_df['stimulus']== 'pretrial_stripe_fix']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pitch_down_WS_decrease = pitch_down.loc[((pitch_down['experimental_condition']=='condition=test'))]\n",
    "\n",
    "#pitch_up_WS_increase = pitch_up.loc[((pitch_up['experimental_condition']=='condition=test'))]\n",
    "\n",
    "#roll_cw_right_increase = roll_cw.loc[((roll_cw['experimental_condition']=='condition=test'))]#\n",
    "\n",
    "#roll_ccw_left_increase = roll_ccw.loc[((roll_ccw['experimental_condition']=='condition=test'))]\n",
    "\n",
    "#yaw_right_right_increase = yaw_right.loc[((yaw_right['experimental_condition']=='condition=test'))]\n",
    "\n",
    "#yaw_left_left_increase = yaw_left.loc[((yaw_left['experimental_condition']=='condition=test'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "X, _ = load_digits(return_X_y=True)\n",
    "transformer = FactorAnalysis(n_components=7, random_state=0)\n",
    "X_transformed = transformer.fit_transform(X)\n",
    "X_transformed.shape\n",
    "(1797, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg\n",
    "\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from sklearn.covariance import ShrunkCovariance, LedoitWolf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, feature_labels=None, estimator_params=None):\n",
    "        \"\"\"Fits an Sklearn FA model to X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data.\n",
    "\n",
    "        feature_labels : array-like, shape (n_features), optional\n",
    "                         Labels for each of the features in X.\n",
    "\n",
    "        estimator_params : dict, optional\n",
    "                           The parameters to pass to Sklearn's FA estimators.\n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "        self._reset()\n",
    "        if feature_labels is None:\n",
    "            feature_labels = [\"feature_{}\".format(i) for i in range(X.shape[1])]   # feature labels being the muscles in this case? sorted_keys\n",
    "        self.feature_labels_ = feature_labels\n",
    "        self.model_ = SklearnFactorAnalysis()\n",
    "        if estimator_params is not None:\n",
    "            # Update Sklearn estimator params\n",
    "            assert isinstance(estimator_params, dict)   ##make estimator params muscles dict?\n",
    "            self.model_.set_params(**estimator_params)\n",
    "        self.model_.fit(X)\n",
    "\n",
    "        # Remove zero-valued components (n_components x n_features)\n",
    "        components_mask = np.sum(self.model_.components_ != 0.0, axis=1) > 0.0\n",
    "        self.components_ = self.model_.components_[components_mask]\n",
    "\n",
    "        # Compute the % variance explained (with/without noise)\n",
    "        c2 = np.sum(self.components_ ** 2, axis=1)\n",
    "        self.total_variance_ = np.sum(c2)\n",
    "        self.pvars_ = 100 * c2 / self.total_variance_\n",
    "        self.pvars_noise_ = 100 * c2 / (self.total_variance_ +\n",
    "                                        np.sum(self.model_.noise_variance_))\n",
    "        return self "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_df= pd.DataFrame()\n",
    "select_df['left_amp'] = multi_fly_df['left_amp']\n",
    "#select_df['right_amp'] = multi_fly_df['right_amp']\n",
    "select_df['i1_left'] = multi_fly_df['i1_left']\n",
    "#select_df['i1_right'] = multi_fly_df['i1_right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['t', 'stimulus', 'amp_diff', 'left_amp', 'right_amp', 'fly_num',\n",
       "       'wbf', 'experimental_condition', 'pr_left', 'tpd_left', 'nm_left',\n",
       "       'iii1_left', 'iii3_left', 'i2_left', 'hg2_left', 'hg3_left',\n",
       "       'hg1_left', 'i1_left', 'bkg_left', 'b1_left', 'b2_left', 'b3_left',\n",
       "       'iii24_left', 'hg4_left', 'pr_right', 'tpd_right', 'nm_right',\n",
       "       'iii1_right', 'iii3_right', 'i2_right', 'hg2_right', 'hg3_right',\n",
       "       'hg1_right', 'i1_right', 'bkg_right', 'b1_right', 'b2_right',\n",
       "       'b3_right', 'iii24_right', 'hg4_right'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WSA_increase \n",
    "#left_turn\n",
    "#right_turn\n",
    "#WSA_decrease\n",
    "\n",
    "yaw_left.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cull_list = [('left', 'bkg'), ('right', 'bkg'),  #('left', 'bkg'),\n",
    "#            ('left', 'iii24'),('right', 'iii24'),\n",
    "#            ('left', 'nm'),('right', 'nm'),\n",
    "#            ('left', 'pr'),('right', 'pr'),\n",
    "#            ('left', 'tpd'),('right', 'tpd')]\n",
    "\n",
    "#[sorted_keys.remove(cull) for cull in cull_list]\n",
    "\n",
    "#for cull in cull_list:\n",
    "#   yaw_left = yaw_left.drop([cull[1]+'_'+cull[0]], axis=1)\n",
    "\n",
    "### things above no longer necessary\n",
    "\n",
    "\n",
    "yaw_left = yaw_left.drop(['t'], axis = 1)\n",
    "yaw_left = yaw_left.drop(['stimulus'], axis =1)\n",
    "yaw_left = yaw_left.drop(['amp_diff'], axis= 1)\n",
    "yaw_left = yaw_left.drop(['left_amp'], axis = 1) \n",
    "yaw_left = yaw_left.drop(['right_amp'], axis =1) \n",
    "yaw_left = yaw_left.drop(['fly_num'], axis =1) \n",
    "yaw_left = yaw_left.drop(['wbf'], axis =1)\n",
    "yaw_left = yaw_left.drop(['experimental_condition'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81584, 32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(yaw_left)\n",
    "np.shape(yaw_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-c445edc219ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfactor_yaw_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFactorAnalysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myaw_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/imager/.local/lib/python2.7/site-packages/sklearn/decomposition/factor_analysis.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \"\"\"\n\u001b[0;32m--> 158\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/imager/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    451\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/imager/.local/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     42\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     43\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 44\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "factor_yaw_left = FactorAnalysis().fit(yaw_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = yaw_left.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'factor_yaw_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-22554a472bd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_yaw_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'factor_yaw_left' is not defined"
     ]
    }
   ],
   "source": [
    "d = pd.DataFrame(factor_yaw_left.components_,columns = col_names)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-bacbb9dca200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'heat_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlayout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'heat_map'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#norm=LogNorm(vmin=Z.min(), vmax=Z.max()), cmap='PuBu_r')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "layout = fifi.FigureLayout('activity_heatmap_layout.svg',make_mplfigures = True)\n",
    "\n",
    "#layout.axes['ind_cell_A_ts_1'].plot(times[1500:1600]-times[1500],cell_A_ind_F_1[1500:1600])\n",
    "#layout.axes['ind_cell_B_ts_1'].plot(times[1500:1600]-times[1500],cell_B_ind_F_1[1500:1600])\n",
    "\n",
    "#layout.axes['coup_cell_A_ts_1'].plot(times[1500:1600]-times[1500],cell_A_coup_F_1[1500:1600]#)\n",
    "#layout.axes['coup_cell_B_ts_1'].plot(times[1500:1600]-times[1500],cell_B_coup_F_1[1500:1600])\n",
    "\n",
    "\n",
    "for col in col_names: \n",
    "    layout.axes['heat_map'].plot(d[col], 'o')\n",
    "    layout.axes['heat_map'].plot(d[col])\n",
    "#norm=LogNorm(vmin=Z.min(), vmax=Z.max()), cmap='PuBu_r')\n",
    "#fig.colorbar(c, ax=ax0)\n",
    "\n",
    "\n",
    "\n",
    "#norm = matplotlib.colors.Normalize(vmin=Min, vmax=Max)\n",
    "#color=cmap(norm(full_matrix_2))\n",
    "#sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "#sm.set_array([])  # only needed for matplotlib < 3.1\n",
    "#fig.colorbar(sm)\n",
    "\n",
    "fifi.mpl_functions.set_spines(layout)\n",
    "layout.save('factor_analysis_yaw_left.svg')\n",
    "plt.close('all')\n",
    "display(SVG('factor_analysis_yaw_left.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "def varimax(Phi, gamma = 1, q = 20, tol = 1e-6):\n",
    "    from numpy import eye, asarray, dot, sum, diag\n",
    "    from numpy.linalg import svd\n",
    "    p,k = Phi.shape\n",
    "    R = eye(k)\n",
    "    d=0\n",
    "    for i in xrange(q):\n",
    "        d_old = d\n",
    "        Lambda = dot(Phi, R)\n",
    "        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda))))))\n",
    "        R = dot(u,vh)\n",
    "        d = sum(s)\n",
    "        if d/d_old < tol: break\n",
    "    return dot(Phi, R)\n",
    "\n",
    "#fa = FactorAnalyzer()\n",
    "#fa.analyze(d, 6, rotation=\"varimax\")\n",
    "\n",
    "v = varimax(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-5881761f4cde>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-5881761f4cde>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def promax (Phi, gamma =1, q= 6, tol = 1e -6):\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## turn this into promax rotation\n",
    "### keep track on the factors in rotation \n",
    "\n",
    "\n",
    "def promax (Phi, gamma =1, q= 6, tol = 1e -6):\n",
    "    from numpy import eye, asarray, dot, sum, diag\n",
    "    from numpy.linalg import svd\n",
    "    p,k = Phi.shape\n",
    "\n",
    "\n",
    "def varimax(Phi, gamma = 1, q = 20, tol = 1e-6):\n",
    "    from numpy import eye, asarray, dot, sum, diag\n",
    "    from numpy.linalg import svd\n",
    "    p,k = Phi.shape\n",
    "    R = eye(k)\n",
    "    d=0\n",
    "    for i in xrange(q):\n",
    "        d_old = d\n",
    "        Lambda = dot(Phi, R)\n",
    "        u,s,vh = svd(dot(Phi.T,asarray(Lambda)**3 - (gamma/p) * dot(Lambda, diag(diag(dot(Lambda.T,Lambda))))))\n",
    "        R = dot(u,vh)\n",
    "        d = sum(s)\n",
    "        if d/d_old < tol: break\n",
    "    return dot(Phi, R)\n",
    "\n",
    "#fa = FactorAnalyzer()\n",
    "#fa.analyze(d, 6, rotation=\"varimax\")\n",
    "\n",
    "v = varimax(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = d #fa.components_\n",
    "n = v #fa.noise_variance_\n",
    "\n",
    "m1 = m**2\n",
    "\n",
    "m2 = np.sum(m1,axis=1)\n",
    "\n",
    "pvar1 = (100*m2[0])/np.sum(m2)\n",
    "pvar2 = (100*m2[1])/np.sum(m2)\n",
    "pvar3 = (100*m2[2])/np.sum(m2)\n",
    "pvar4 = (100*m2[3])/np.sum(m2)\n",
    "pvar5 = (100*m2[4])/np.sum(m2)\n",
    "pvar6 = (100*m2[5])/np.sum(m2)\n",
    "pvar7 = (100*m2[6])/np.sum(m2)\n",
    "pvar8 = (100*m2[7])/np.sum(m2)\n",
    "pvar9 = (100*m2[8])/np.sum(m2)\n",
    "pvar10 = (100*m2[9])/np.sum(m2)\n",
    "pvar11 = (100*m2[10])/np.sum(m2)\n",
    "pvar12 = (100*m2[11])/np.sum(m2)\n",
    "pvar13 = (100*m2[12])/np.sum(m2)\n",
    "pvar14 = (100*m2[13])/np.sum(m2)\n",
    "pvar15 = (100*m2[14])/np.sum(m2)\n",
    "pvar16 = (100*m2[15])/np.sum(m2)\n",
    "pvar17 = (100*m2[16])/np.sum(m2)\n",
    "pvar18 = (100*m2[17])/np.sum(m2)\n",
    "pvar19 = (100*m2[18])/np.sum(m2)\n",
    "pvar20 = (100*m2[19])/np.sum(m2)\n",
    "pvar21 = (100*m2[20])/np.sum(m2)\n",
    "pvar22 = (100*m2[21])/np.sum(m2)\n",
    "\n",
    "\n",
    "pvar1_with_noise = (100*m2[0])/(np.sum(m2)+np.sum(n))\n",
    "pvar2_with_noise = (100*m2[1])/(np.sum(m2)+np.sum(n))\n",
    "\n",
    "per_dav_df = pd.DataFrame()\n",
    "per_dav_df['pvars']= [pvar1 , pvar2, pvar3, pvar4, pvar5, pvar6, pvar7, pvar8, pvar9, pvar10, pvar11, pvar12, pvar13, pvar14, pvar15, pvar16, pvar17, pvar18, pvar19, pvar20, pvar21, pvar22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvar7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Percentage of variance explained by each factor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np; np.random.seed(0)\n",
    "import pandas as pd\n",
    "\n",
    "#x = list(pitch_down_new_df['muscles'])\n",
    "x = np.arange(22)\n",
    "y = list(per_dav_df['pvars'])#*(10^160))\n",
    "c = list(per_dav_df['pvars'])#*(10^160))\n",
    "df = pd.DataFrame({\"x\":x,\"y\":y,\"c\":c})\n",
    "\n",
    "cmap = plt.cm.rainbow\n",
    "#norm = matplotlib.colors.Normalize(vmin=Min, vmax=Max)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(df.x, df.y, color=cmap((df.c.values)))\n",
    "ax.set_xticks(df.x)\n",
    "\n",
    "sm = plt.cm.ScalarMappable(cmap=cmap)#, norm=norm)\n",
    "sm.set_array([])  # only needed for matplotlib < 3.1\n",
    "fig.colorbar(sm)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement different factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Normalize prior to rotations/ factor analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_tonic_range(data):\n",
    "    data = data\n",
    "    # best fit of data\n",
    "    (mu, sigma) = norm.fit(data)\n",
    "\n",
    "    # the histogram of the data\n",
    "    n, bins, patches = plt.hist(data, 100, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "    # add a 'best fit' line\n",
    "    y = mlab.normpdf( bins, mu, sigma)\n",
    "    #l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "\n",
    "    mmin = mu - (2*sigma)\n",
    "    mmax = mu + (2*sigma)\n",
    "    \n",
    "    return (mu, sigma, mmin, mmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normd_mods(muscle_data):\n",
    "        mu, sigma, mmin, mmax = min_max_tonic_range(muscle_data)\n",
    "        xno = muscle_data\n",
    "        normalized = (xno-mmin)/(max(xno)-mmin)\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imager/.local/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/mlab.py:1587: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return 1./(np.sqrt(2*np.pi)*sigma)*np.exp(-0.5 * (1./sigma*(x - mu))**2)\n",
      "/usr/lib/python2.7/dist-packages/matplotlib/mlab.py:1587: RuntimeWarning: invalid value encountered in multiply\n",
      "  return 1./(np.sqrt(2*np.pi)*sigma)*np.exp(-0.5 * (1./sigma*(x - mu))**2)\n"
     ]
    }
   ],
   "source": [
    "normed_multi_fly_df = pd.DataFrame()\n",
    "\n",
    "for flynum in fly_nums:\n",
    "    df=multi_fly_df.loc[multi_fly_df['fly_num']==flynum]\n",
    "    for key in sorted_keys: \n",
    "        a = normd_mods(df[key])\n",
    "        df[key] = a\n",
    "    normed_multi_fly_df = normed_multi_fly_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_left = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'yaw_left, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "yaw_right = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'yaw_right, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "pitch_up = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'pitch_up_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "pitch_down = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'pitch_down_actually_roll, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "roll_cw = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'roll_clockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "roll_ccw = normed_multi_fly_df.loc[normed_multi_fly_df['stimulus']== 'roll_counterclockwise_actually_pitch, g_x=12, g_y=0, b_x=0, b_y=0, ch=0']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_left = yaw_left.fillna(0)\n",
    "yaw_right = yaw_right.fillna(0)\n",
    "pitch_up = pitch_up.fillna(0)\n",
    "pitch_down = pitch_down.fillna(0)\n",
    "roll_cw = roll_cw.fillna(0)\n",
    "roll_ccw = roll_ccw.fillna(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cull_list = [('left', 'bkg'), ('right', 'bkg'),  #('left', 'bkg'),\n",
    "            ('left', 'iii24'),('right', 'iii24'),\n",
    "            ('left', 'nm'),('right', 'nm'),\n",
    "            ('left', 'pr'),('right', 'pr'),\n",
    "            ('left', 'tpd'),('right', 'tpd')]\n",
    "\n",
    "#[sorted_keys.remove(cull) for cull in cull_list]\n",
    "\n",
    "for cull in cull_list:\n",
    "    yaw_left = yaw_left.drop([cull[1]+'_'+cull[0]], axis=1)\n",
    "\n",
    "WSA_increase = WSA_increase.drop(['t'], axis = 1)\n",
    "WSA_increase = WSA_increase.drop(['stimulus'], axis =1)\n",
    "WSA_increase = WSA_increase.drop(['amp_diff'], axis= 1)\n",
    "WSA_increase = WSA_increase.drop(['left_amp'], axis = 1) \n",
    "WSA_increase = WSA_increase.drop(['right_amp'], axis =1) \n",
    "WSA_increase = WSA_increase.drop(['fly_num'], axis =1) \n",
    "WSA_increase = WSA_increase.drop(['wbf'], axis =1)\n",
    "WSA_increase = WSA_increase.drop(['experimental_condition'], axis=1)\n",
    "\n",
    "\n",
    "type(WSA_increase)\n",
    "np.shape(WSA_increase)\n",
    "\n",
    "\n",
    "factor_WSA_inc = FactorAnalysis().fit(WSA_increase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "othrogonal\n",
    "vs \n",
    "oblique\n",
    "vs\n",
    "varimax rotations\n",
    "\n",
    "normalization of matrices and correlations\n",
    "\n",
    "all rotations to extract relevant features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add oblique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
